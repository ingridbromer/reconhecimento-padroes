{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d888dd3e-0d24-4c7f-a852-e6449a6181da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aumentando classe POSITIVE com 1205 imagens RGB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▉                                                                            | 121/3300 [00:01<00:52, 60.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aumento de dados RGB concluído. Total gerado: 1205\n",
      "Aumentando classe POSITIVE com 1205 imagens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▉                                                                            | 121/3300 [00:01<00:34, 91.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aumento de dados concluído. Total gerado: 1205\n",
      " Processamento completo com balanceamento, augmentations e normalização segura.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mahotas\n",
    "from tqdm import tqdm\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import regionprops, label\n",
    "from skimage import morphology\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ========== CAMINHOS ==========\n",
    "#base_dir = \"/Users/xr4good/Documents/Ingrid/datasets/imagens/base\"\n",
    "#json_path = os.path.join(base_dir, \"classifications_2classes.json\")\n",
    "#output_dir_treino = \"/Users/xr4good/Documents/Ingrid/datasets/imagens/treino/treino/2classes\"\n",
    "#output_dir_val = \"/Users/xr4good/Documents/Ingrid/datasets/imagens/validacao/validacao/2classes/\"\n",
    "#output_dir_teste = \"/Users/xr4good/Documents/Ingrid/datasets/imagens/teste/teste/2classes/\"\n",
    "base_dir = \"E:/datasets/imagens/base\"\n",
    "json_path = os.path.join(base_dir, \"classifications_2classes.json\")\n",
    "output_dir_treino = \"E:/datasets/imagens/treino/treino/2classes\"\n",
    "output_dir_val = \"E:/datasets/imagens/validacao/validacao/2classes/\"\n",
    "output_dir_teste = \"E:/datasets/imagens/teste/teste/2classes/\"\n",
    "\n",
    "# ========== CRIAR DIRETÓRIOS ==========\n",
    "train_neg_dir_rgb = os.path.join(output_dir_treino, \"treino-dir-negativo-rgb\")\n",
    "train_pos_dir_rgb = os.path.join(output_dir_treino, \"treino-dir-positivo-rgb\")\n",
    "val_pos_dir_rgb = os.path.join(output_dir_val, \"validacao-dir-positivo-rgb\")\n",
    "val_neg_dir_rgb = os.path.join(output_dir_val, \"validacao-dir-negativo-rgb\")\n",
    "test_pos_dir_rgb = os.path.join(output_dir_teste, \"teste-dir-positivo-rgb\")\n",
    "test_neg_dir_rgb = os.path.join(output_dir_teste, \"teste-dir-negativo-rgb\")\n",
    "train_neg_dir = os.path.join(output_dir_treino, \"treino-dir-negativo\")\n",
    "train_pos_dir = os.path.join(output_dir_treino, \"treino-dir-positivo\")\n",
    "val_pos_dir = os.path.join(output_dir_val, \"validacao-dir-positivo\")\n",
    "val_neg_dir = os.path.join(output_dir_val, \"validacao-dir-negativo\")\n",
    "test_pos_dir = os.path.join(output_dir_teste, \"teste-dir-positivo\")\n",
    "test_neg_dir = os.path.join(output_dir_teste, \"teste-dir-negativo\")\n",
    "\n",
    "for d in [train_neg_dir, train_pos_dir, val_pos_dir, val_neg_dir, test_pos_dir, test_neg_dir]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "# Criar diretórios RGB\n",
    "for d in [train_neg_dir_rgb, train_pos_dir_rgb, val_pos_dir_rgb, val_neg_dir_rgb, test_pos_dir_rgb, test_neg_dir_rgb]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# ========== CARREGAR JSON ==========\n",
    "with open(json_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# ========== EXTRATO DE CÉLULAS ==========\n",
    "all_cells = []\n",
    "for img_data in data:\n",
    "    image_name = img_data[\"image_name\"]\n",
    "    for cell in img_data[\"classifications\"]:\n",
    "        all_cells.append({\n",
    "            \"image_name\": image_name,\n",
    "            \"cell_id\": cell[\"cell_id\"],\n",
    "            \"x\": cell[\"nucleus_x\"],\n",
    "            \"y\": cell[\"nucleus_y\"],\n",
    "            \"label\": cell[\"bethesda_system\"]\n",
    "        })\n",
    "\n",
    "# ========== DIVISÃO ENTRE POS/NEG ==========\n",
    "positive_cells = [c for c in all_cells if c[\"label\"] == \"POSITIVE\"]\n",
    "negative_cells = [c for c in all_cells if c[\"label\"] != \"POSITIVE\"]\n",
    "\n",
    "# ========== DIVISÃO TREINO/VAL/TEST POR IMAGEM ==========\n",
    "random.seed(42)\n",
    "# Shuffle global\n",
    "random.seed(42)\n",
    "\n",
    "# Separar por classe\n",
    "positive_cells = [c for c in all_cells if c[\"label\"] == \"POSITIVE\"]\n",
    "negative_cells = [c for c in all_cells if c[\"label\"] != \"POSITIVE\"]\n",
    "\n",
    "random.shuffle(positive_cells)\n",
    "random.shuffle(negative_cells)\n",
    "\n",
    "# Split por classe individualmente\n",
    "def split_data(cells):\n",
    "    total = len(cells)\n",
    "    n_train = int(0.7 * total)\n",
    "    n_val = int(0.15 * total)\n",
    "    train = cells[:n_train]\n",
    "    val = cells[n_train:n_train + n_val]\n",
    "    test = cells[n_train + n_val:]\n",
    "    return train, val, test\n",
    "\n",
    "# Aplicar split\n",
    "train_pos, val_pos, test_pos = split_data(positive_cells)\n",
    "train_neg, val_neg, test_neg = split_data(negative_cells)\n",
    "\n",
    "\n",
    "# ========== SALVAR RECORTES ==========\n",
    "usadas = {k: 0 for k in [\"train_pos\", \"train_neg\", \"val_pos\", \"val_neg\", \"test_pos\", \"test_neg\"]}\n",
    "descartadas = 0\n",
    "gray_dirs = {\n",
    "    \"train_pos\": train_pos_dir,\n",
    "    \"train_neg\": train_neg_dir,\n",
    "    \"val_pos\": val_pos_dir,\n",
    "    \"val_neg\": val_neg_dir,\n",
    "    \"test_pos\": test_pos_dir,\n",
    "    \"test_neg\": test_neg_dir\n",
    "}\n",
    "\n",
    "rgb_dirs = {\n",
    "    \"train_pos\": train_pos_dir_rgb,\n",
    "    \"train_neg\": train_neg_dir_rgb,\n",
    "    \"val_pos\": val_pos_dir_rgb,\n",
    "    \"val_neg\": val_neg_dir_rgb,\n",
    "    \"test_pos\": test_pos_dir_rgb,\n",
    "    \"test_neg\": test_neg_dir_rgb\n",
    "}\n",
    "def balancear_treinamento_rgb(positivos_dir_rgb, negativos_dir_rgb):\n",
    "    pos_files = [f for f in os.listdir(positivos_dir_rgb) if f.endswith(\".png\")]\n",
    "    neg_files = [f for f in os.listdir(negativos_dir_rgb) if f.endswith(\".png\")]\n",
    "    qtd_pos, qtd_neg = len(pos_files), len(neg_files)\n",
    "\n",
    "    if qtd_pos < qtd_neg:\n",
    "        deficit = qtd_neg - qtd_pos\n",
    "        base_dir = positivos_dir_rgb\n",
    "        base_files = pos_files\n",
    "        classe = \"POSITIVE\"\n",
    "    elif qtd_neg < qtd_pos:\n",
    "        deficit = qtd_pos - qtd_neg\n",
    "        base_dir = negativos_dir_rgb\n",
    "        base_files = neg_files\n",
    "        classe = \"NEGATIVE\"\n",
    "    else:\n",
    "        print(\"Classes já estão balanceadas.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Aumentando classe {classe} com {deficit} imagens RGB...\")\n",
    "\n",
    "    contador = 0\n",
    "    for f in tqdm(base_files):\n",
    "        if contador >= deficit:\n",
    "            break\n",
    "        path = os.path.join(base_dir, f)\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")  # Abre como RGB\n",
    "            for i, aug in enumerate(apply_augmentations(img)):\n",
    "                if contador >= deficit:\n",
    "                    break\n",
    "                out_name = f\"{os.path.splitext(f)[0]}_aug{i+1}.png\"\n",
    "                aug.save(os.path.join(base_dir, out_name))\n",
    "                contador += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar {path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"Aumento de dados RGB concluído. Total gerado: {contador}\")\n",
    "\n",
    "def save_cropped_dual(cell, image_dir, key):\n",
    "    global descartadas\n",
    "    image_path = os.path.join(image_dir, cell[\"image_name\"])\n",
    "    if not os.path.exists(image_path):\n",
    "        descartadas += 1\n",
    "        return\n",
    "    try:\n",
    "        # Abrir em RGB e em escala de cinza\n",
    "        img_rgb = Image.open(image_path).convert(\"RGB\")\n",
    "        img_gray = img_rgb.convert(\"L\")\n",
    "    except:\n",
    "        descartadas += 1\n",
    "        return\n",
    "    x, y = cell[\"x\"], cell[\"y\"]\n",
    "    half_crop = 35\n",
    "    if x - half_crop < 0 or y - half_crop < 0 or x + half_crop > img_rgb.width or y + half_crop > img_rgb.height:\n",
    "        descartadas += 1\n",
    "        return\n",
    "\n",
    "    # Recortar ambas as versões\n",
    "    crop_rgb = img_rgb.crop((x - half_crop, y - half_crop, x + half_crop, y + half_crop))\n",
    "    crop_gray = img_gray.crop((x - half_crop, y - half_crop, x + half_crop, y + half_crop))\n",
    "\n",
    "    name = f\"{os.path.splitext(cell['image_name'])[0]}_celula_{cell['cell_id']}.png\"\n",
    "\n",
    "    # Salvar\n",
    "    crop_rgb.save(os.path.join(rgb_dirs[key], name))\n",
    "    crop_gray.save(os.path.join(gray_dirs[key], name))\n",
    "    usadas[key] += 1\n",
    "\n",
    "for c in train_pos: save_cropped_dual(c, base_dir, \"train_pos\")\n",
    "for c in train_neg: save_cropped_dual(c, base_dir, \"train_neg\")\n",
    "for c in val_pos: save_cropped_dual(c, base_dir, \"val_pos\")\n",
    "for c in val_neg: save_cropped_dual(c, base_dir, \"val_neg\")\n",
    "for c in test_pos: save_cropped_dual(c, base_dir, \"test_pos\")\n",
    "for c in test_neg: save_cropped_dual(c, base_dir, \"test_neg\")\n",
    "\n",
    "balancear_treinamento_rgb(train_pos_dir_rgb, train_neg_dir_rgb)\n",
    "\n",
    "\n",
    "# ========== TRANSFORMAÇÕES ==========\n",
    "def apply_augmentations(img):\n",
    "    return [\n",
    "        # Rotações em ângulos fixos (15, 90°, 180° e 270°)\n",
    "        img.rotate(15),\n",
    "        img.rotate(90),\n",
    "        img.rotate(180),\n",
    "        img.rotate(270),\n",
    "        # Espelhamento horizontal e vertifcal\n",
    "        img.transpose(Image.FLIP_LEFT_RIGHT),\n",
    "        img.transpose(Image.FLIP_TOP_BOTTOM),\n",
    "        # Ajustes de contraste e nitidez\n",
    "        ImageEnhance.Contrast(img).enhance(1.5),\n",
    "        ImageEnhance.Sharpness(img).enhance(2),\n",
    "        # Filtros de desfoque, como o desfoque Gaussiano e o filtro da mediana\n",
    "        img.filter(ImageFilter.GaussianBlur(radius=1)),\n",
    "        img.filter(ImageFilter.MedianFilter(size=3)),\n",
    "    ]\n",
    "\n",
    "def balancear_treinamento_automaticamente(positivos_dir, negativos_dir):\n",
    "    pos_files = [f for f in os.listdir(positivos_dir) if f.endswith(\".png\")]\n",
    "    neg_files = [f for f in os.listdir(negativos_dir) if f.endswith(\".png\")]\n",
    "    qtd_pos, qtd_neg = len(pos_files), len(neg_files)\n",
    "\n",
    "    if qtd_pos < qtd_neg:\n",
    "        deficit = qtd_neg - qtd_pos\n",
    "        base_dir = positivos_dir\n",
    "        base_files = pos_files\n",
    "        classe = \"POSITIVE\"\n",
    "    elif qtd_neg < qtd_pos:\n",
    "        deficit = qtd_pos - qtd_neg\n",
    "        base_dir = negativos_dir\n",
    "        base_files = neg_files\n",
    "        classe = \"NEGATIVE\"\n",
    "    else:\n",
    "        print(\"Classes já estão balanceadas.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Aumentando classe {classe} com {deficit} imagens...\")\n",
    "\n",
    "    contador = 0\n",
    "    for f in tqdm(base_files):\n",
    "        if contador >= deficit:\n",
    "            break\n",
    "        path = os.path.join(base_dir, f)\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"L\")\n",
    "            for i, aug in enumerate(apply_augmentations(img)):\n",
    "                if contador >= deficit:\n",
    "                    break\n",
    "                out_name = f\"{os.path.splitext(f)[0]}_aug{i+1}.png\"\n",
    "                aug.save(os.path.join(base_dir, out_name))\n",
    "                contador += 1\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(f\"Aumento de dados concluído. Total gerado: {contador}\")\n",
    "\n",
    "balancear_treinamento_automaticamente(train_pos_dir, train_neg_dir)\n",
    "\n",
    "# ========== EXTRAÇÃO DE ATRIBUTOS ==========\n",
    "def extrair_atributos(p):\n",
    "    img = imread(p, as_gray=True)\n",
    "    img_u8 = (img * 255).astype(np.uint8)\n",
    "\n",
    "    try:\n",
    "        bin = morphology.remove_small_objects(img > threshold_otsu(img), 30)\n",
    "        props = regionprops(label(bin))\n",
    "        if props:\n",
    "            p = props[0]\n",
    "            area, perim = p.area, p.perimeter\n",
    "            ecc = p.eccentricity\n",
    "            circ = 4*np.pi*area/(perim**2) if perim > 0 else 0\n",
    "            elip = p.major_axis_length/p.minor_axis_length if p.minor_axis_length > 0 else 0\n",
    "        else:\n",
    "            area = perim = ecc = circ = elip = 0\n",
    "    except:\n",
    "        area = perim = ecc = circ = elip = 0\n",
    "\n",
    "    mean, std, skw, krt = img.mean(), img.std(), skew(img.ravel()), kurtosis(img.ravel())\n",
    "    ent = -np.sum(img * np.log2(img + 1e-10))\n",
    "\n",
    "    glcm = graycomatrix(img_u8, [1], [0], symmetric=True, normed=True)\n",
    "    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "    corr = graycoprops(glcm, 'correlation')[0, 0]\n",
    "    energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "    homog = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "\n",
    "    lbp = local_binary_pattern(img, 8, 1, method='uniform')\n",
    "    lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), density=True)\n",
    "\n",
    "    hrlk = mahotas.features.haralick(img_u8).mean(axis=0)\n",
    "    tas = mahotas.features.tas(img_u8)\n",
    "    zern = mahotas.features.zernike_moments(img_u8, radius=min(img.shape)//2, degree=8)\n",
    "    \n",
    "    # ===== DESCRITORES DE FOURIER =====\n",
    "    fft = np.fft.fft2(img)\n",
    "    fft_shift = np.fft.fftshift(fft)\n",
    "    magnitude_spectrum = np.abs(fft_shift)\n",
    "\n",
    "    # Normalização para evitar overflow\n",
    "    magnitude_spectrum /= (magnitude_spectrum.max() + 1e-10)\n",
    "\n",
    "    # Estatísticas do espectro\n",
    "    fft_mean = magnitude_spectrum.mean()\n",
    "    fft_std = magnitude_spectrum.std()\n",
    "    fft_energy = np.sum(magnitude_spectrum**2)\n",
    "    fft_entropy = -np.sum(magnitude_spectrum * np.log2(magnitude_spectrum + 1e-10))\n",
    "\n",
    "    return np.hstack([\n",
    "        area, perim, ecc, circ, elip,\n",
    "        mean, std, skw, krt, ent,\n",
    "        contrast, corr, energy, homog,\n",
    "        lbp_hist, hrlk, tas, zern,  fft_mean, fft_std, fft_energy, fft_entropy\n",
    "    ])\n",
    "\n",
    "# ========== CSV COM NORMALIZAÇÃO BASEADA NO TREINO ==========\n",
    "def gerar_df_csv(diretorio, label):\n",
    "    linhas = []\n",
    "    for arq in os.listdir(diretorio):\n",
    "        if arq.endswith(\".png\"):\n",
    "            path = os.path.normpath(os.path.join(diretorio, arq))\n",
    "            feat = extrair_atributos(path)\n",
    "            base = os.path.splitext(arq)[0].split(\"_celula_\")\n",
    "            linhas.append([base[0], base[1] if len(base)>1 else \"NA\"] + list(feat) + [label])\n",
    "    df = pd.DataFrame(linhas)\n",
    "    df.columns = [\"image_name\", \"cell_id\"] + [f\"feat_{i}\" for i in range(len(linhas[0])-3)] + [\"label\"]\n",
    "    return df\n",
    "\n",
    "def normalizar_e_salvar(df_train, df_val, df_test):\n",
    "    col_attr = df_train.columns[2:-1]\n",
    "    scaler = MinMaxScaler().fit(df_train[col_attr])\n",
    "    df_train[col_attr] = scaler.transform(df_train[col_attr])\n",
    "    df_val[col_attr] = scaler.transform(df_val[col_attr])\n",
    "    df_test[col_attr] = scaler.transform(df_test[col_attr])\n",
    "    df_train.to_csv(\"train_2classes.csv\", index=False)\n",
    "    df_val.to_csv(\"val_2classes.csv\", index=False)\n",
    "    df_test.to_csv(\"test_2classes.csv\", index=False)\n",
    "\n",
    "df_train = pd.concat([\n",
    "    gerar_df_csv(train_pos_dir, 1),\n",
    "    gerar_df_csv(train_neg_dir, 0)\n",
    "], ignore_index=True).sample(frac=1, random_state=42)\n",
    "\n",
    "df_val = pd.concat([\n",
    "    gerar_df_csv(val_pos_dir, 1),\n",
    "    gerar_df_csv(val_neg_dir, 0)\n",
    "], ignore_index=True).sample(frac=1, random_state=42)\n",
    "\n",
    "df_test = pd.concat([\n",
    "    gerar_df_csv(test_pos_dir, 1),\n",
    "    gerar_df_csv(test_neg_dir, 0)\n",
    "], ignore_index=True).sample(frac=1, random_state=42)\n",
    "\n",
    "normalizar_e_salvar(df_train, df_val, df_test)\n",
    "\n",
    "print(\" Processamento completo com balanceamento, augmentations e normalização segura.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b6005b-1d4b-4f7f-baca-90bab09f1396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
